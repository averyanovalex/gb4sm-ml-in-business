{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашка 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
    "\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
    "Допустим, у нас две модели:\n",
    "\n",
    "- первая помечает 100 объектов как класс 1, но TP = 90\n",
    "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_case2.csv', ';')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52500, 12), (52500,), (17500, 12), (17500,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', 1), \n",
    "                                                    df['cardio'], random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "for cat_col in cat_cols:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=base_col))\n",
    "            ])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = {'Логистичиская регрессия': LogisticRegression(random_state = 42),\n",
    "               'Градиентный бустинг': GradientBoostingClassifier(random_state = 42),\n",
    "               'Случайный лес': RandomForestClassifier(random_state = 42),\n",
    "              }\n",
    "\n",
    "models = []\n",
    "for key in model_types:\n",
    "    \n",
    "    classifier = Pipeline([\n",
    "        ('features',feats),\n",
    "        ('classifier', model_types[key]),\n",
    "    ])\n",
    "    \n",
    "    model = {'title': key, 'classifier': classifier}\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Логистичиская регрессия.\tCV score is 0.7867401104915408+-0.00852135511666111\n",
      "Model: Градиентный бустинг.\tCV score is 0.8025124517417064+-0.007075372179995901\n",
      "Model: Случайный лес.\tCV score is 0.7734501681056019+-0.007171140345435727\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#обучим наши модели\n",
    "for model in models:\n",
    "    \n",
    "    classifier = model['classifier']\n",
    "    \n",
    "    #запустим кросс-валидацию\n",
    "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "    print('Model: {}.\\tCV score is {}+-{}'.format(model['title'], cv_score, cv_score_std))\n",
    "\n",
    "    #обучим пайплайн на всем тренировочном датасете\n",
    "    classifier.fit(X_train, y_train)\n",
    "    model['y_score'] = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.386937, F-Score=0.730, Precision=0.647, Recall=0.838. Model: Логистичиская регрессия\n",
      "Best Threshold=0.394947, F-Score=0.740, Precision=0.698, Recall=0.788. Model: Градиентный бустинг\n",
      "Best Threshold=0.350000, F-Score=0.719, Precision=0.643, Recall=0.816. Model: Случайный лес\n"
     ]
    }
   ],
   "source": [
    "for model in models:    \n",
    "    b=1\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test.values, model['y_score'])\n",
    "    fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    model['precision'] = precision[ix] \n",
    "    model['recall'] = recall[ix]\n",
    "    model['fscore'] = fscore[ix]\n",
    "    \n",
    "    print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f. Model: %s' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix],\n",
    "                                                                        model['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score: 0.7840347790421852. Model: Логистичиская регрессия \n",
      "roc auc score: 0.8026153641179974. Model: Градиентный бустинг \n",
      "roc auc score: 0.7710366181802983. Model: Случайный лес \n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    \n",
    "    #странный косяк поймал, если не переинецилизировать каждый раз, выдает ошибку\n",
    "    from sklearn.metrics import roc_auc_score \n",
    "    \n",
    "    roc_auc_score = roc_auc_score(y_true=y_test, y_score=model['y_score'])\n",
    "    model['roc_auc_score'] = roc_auc_score   \n",
    "    print(\"roc auc score: {}. Model: {} \".format(roc_auc_score, model['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>roc auc score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Логистичиская регрессия</th>\n",
       "      <td>0.647431</td>\n",
       "      <td>0.837558</td>\n",
       "      <td>0.730323</td>\n",
       "      <td>0.784035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Градиентный бустинг</th>\n",
       "      <td>0.697848</td>\n",
       "      <td>0.788134</td>\n",
       "      <td>0.740248</td>\n",
       "      <td>0.802615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Случайный лес</th>\n",
       "      <td>0.642669</td>\n",
       "      <td>0.815553</td>\n",
       "      <td>0.718863</td>\n",
       "      <td>0.771037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         precision    recall    fscore  roc auc score\n",
       "Логистичиская регрессия   0.647431  0.837558  0.730323       0.784035\n",
       "Градиентный бустинг       0.697848  0.788134  0.740248       0.802615\n",
       "Случайный лес             0.642669  0.815553  0.718863       0.771037"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# формулируем результирующую таблицу\n",
    "titles = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "roc_aucs = []\n",
    "\n",
    "for model in models:\n",
    "    titles.append(model['title'])\n",
    "    precisions.append(model['precision'])\n",
    "    recalls.append(model['recall'])\n",
    "    fscores.append(model['fscore'])\n",
    "    roc_aucs.append(model['roc_auc_score'])\n",
    "    \n",
    "result = pd.DataFrame({'precision': precisions, 'recall': recalls, 'fscore': fscores, 'roc auc score': roc_aucs}, \n",
    "                          index=titles)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ответим на вопросы\n",
    "\n",
    "__4. сделать выводы о том, какая модель справилась с задачей лучше других__\n",
    "\n",
    "Нельзя сказать однозначно, какая модель справилась лучше. Хотя интегральная оценка `roc_auc_score`, рейтинг по оценкам `precision` и `recall`.  Точность получилась выше у градиентного бустинга выше, но полнота выше у логистической модели и случайного леса. Что объясняется склонность бустинга к переобучению. Логистическая модель наооборот, может показать больший сдвиг, но меньший разброс (более устойчивая). \n",
    "\n",
    "Лес же оказался посередине. С одной стороны по точности он почти равен логистической регрессии, но полнота у него существенно выше.\n",
    "\n",
    "Какая модель лучше справилась с задачей будет определяться задачей. Если нам нужна максимизация точности при заданном уровне полноты, стоит выбрать бустинг. Если максимальная полноста, то возможно лучше подойдет регрессия. Если нужна высокая обучения (логистическая регрессия обучилась в 3 раза быстрее конкурентов) при заданном уровне метрик качества, возможно регрессия подойдет лучше.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого)__\n",
    "\n",
    "Я думаю, что при сильном дисбалансе классов лучше подойдет `precision_recall_curve`. Потому что когда одного класса существенно меньше, чем другого, визуальное отображение кривой `roc_auc_curve` может приводить к неточным выводам. Количество шагов по вертикали будет намного меньше количества шагов по горизонтали. И кривая будет выглядеть не одинаково при отображении значений одного класса и другого класса. \n",
    "\n",
    "`precision_recall_curve` наоборот при любом дисбалансе классов будет выглядеть одинаково. И как графически, так и аналитически можно всегда точно определить удобный порог в зависимости от решаемой задачи и увидеть насколько сильно будут отличаться график в области выбранного порога если немного сместиться влево или вправо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
